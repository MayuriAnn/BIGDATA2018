{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import numpy as np\n",
    "import copy\n",
    "import networkx as nx\n",
    "import os\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = os.path.join('projeto.csv')\n",
    "dataRDD = (sc.textFile(arquivo, 8))\n",
    "RDD1 = dataRDD.map(lambda l: l.split(',')).map(lambda l: {'label':float(l[0]),'features':[float(l[1]),float(l[2]),l[3]]})\n",
    "RDD = RDD1.filter(lambda v: v['label']<=1.61) #removing outliers\n",
    "weights = [.999,.001]\n",
    "seed = 42\n",
    "lpRDD, lpTest = RDD.randomSplit(weights, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparaMMU(t):\n",
    "    \"\"\"Prepares data from the function minmax_unique.\n",
    "\n",
    "    Args:\n",
    "        t (dict): An example from the dataset\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple with tuples for the values of all numeric attributes \n",
    "               and a set of the categorical attribute\n",
    "                 ((attrib0,attrib0),(attrib1,attrib1), set((attrib2,)))\n",
    "    \"\"\"    \n",
    "    return ((t['features'][0],t['features'][0]),(t['features'][1],t['features'][1]), set((t['features'][2],)))\n",
    "    \n",
    "def minmax_unique(t1,t2):\n",
    "    \"\"\"Calculates the min and max of the numeric attributes and \n",
    "       determine the unique categoric values in a single pass on the dataset.\n",
    "\n",
    "    Args:\n",
    "        t1,t2 (tuple): tuples received from the function preparaMMU\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple with values((min value of attrib 0,max value of attrib 0),\n",
    "                                   (min value of attrib 1,max value of attrib 1),\n",
    "                                   {set with unique values of attrib 2})\n",
    "    \"\"\"\n",
    "    return ((min(t1[0][0],t2[0][0]),max(t1[0][1],t2[0][1])),\n",
    "            (min(t1[1][0],t2[1][0]),max(t1[1][1],t2[1][1])),\n",
    "             t1[2].union(t2[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSplits(lpRDD):\n",
    "    \"\"\"Determine splits for all attributes.\n",
    "\n",
    "    Args:\n",
    "        lpRDD (RDD): The dataset. It can be complete or splited.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple with two lists (all_features, all_splits)\n",
    "    \"\"\"\n",
    "    (min0,max0),(min1,max1),periods =lpRDD.map(preparaMMU).reduce(minmax_unique)\n",
    "    \n",
    "    periods = list(periods)\n",
    "\n",
    "    \n",
    "    distsplits = [i*(max0-min0)/5. for i in range(1,5)]\n",
    "    timesplits = [i*(max1-min1)/5. for i in range(1,5)]    \n",
    "    perisplits = [tuple([periods[j] for j in range(i+1)]) for i in range(len(periods)-1)]\n",
    "\n",
    "    feats = [0,1,2,3]\n",
    "    splits = [distsplits,timesplits,perisplits,['full']] \n",
    "    return (feats,splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def contador(lp, feats, splits):\n",
    "    \"\"\"Prepare data for the soma function. Given a feature and a split candidate, returns tuples for the left \n",
    "       and right splits based on the feature and split value.\n",
    "\n",
    "    Args:\n",
    "        lp (dict): An example from the dataset\n",
    "        feats (list): list with features indexes on lp\n",
    "        splits (list): list of lists with splits candidates for all attributes\n",
    "\n",
    "    Returns:\n",
    "        r (list): list of tuples, where each tuple contains:\n",
    "        \n",
    "        for numeric attributes:\n",
    "            ((feat,split),(0,label.value),(0,label.value^2),(0,1)) if feat.value >= split-num\n",
    "            ((feat,split),(label.value,0),(label.value^2,0),(1,0)) if feat.value < split-num\n",
    "        for categoric attributes:\n",
    "            ((feat,split),(0,label.value),(0,label.value^2),(0,1)) if feat.value in split-cat\n",
    "            ((feat,split),(label.value,0),(label.value^2,0),(1,0)) if feat.value not in split-cat\n",
    "        for the target attribute:\n",
    "            ((label,'full'),(0,label.value),(0,label.value^2),(0,1))\n",
    "        \n",
    "    \"\"\"\n",
    "    r = []\n",
    "    for feat in feats:\n",
    "        splitss = splits[feat]\n",
    "        for split in splitss:\n",
    "            if feat==3:\n",
    "                r.append( ((feat,split), ((0,lp['label']), (0,lp['label']**2), (0,1))))\n",
    "            elif feat==0 or feat==1:\n",
    "                if lp['features'][feat] >= split:\n",
    "                    r.append( ((feat,split), ((0,lp['label']), (0,lp['label']**2), (0,1))))\n",
    "                else:\n",
    "                    r.append( ((feat,split), ((lp['label'],0), (lp['label']**2,0), (1,0))))\n",
    "                \n",
    "            elif feat==2:                \n",
    "                if lp['features'][feat] in split:\n",
    "                    r.append( ((feat,split), ((0,lp['label']), (0,lp['label']**2), (0,1))))\n",
    "                else:\n",
    "                    r.append( ((feat,split), ((lp['label'],0), (lp['label']**2,0), (1,0))))\n",
    "                \n",
    "    return r\n",
    "\n",
    "def soma(t1,t2):\n",
    "    \"\"\"Sums tuples with the same key received from contador function using reduceByKey.\n",
    "       Number of tuples returned equals to the sum of the number of splits of each attribute plus one.\n",
    "\n",
    "    Args:\n",
    "        t1 (tuple): A tuple containing values from the left or right split \n",
    "                    or all data for the target value\n",
    "        t2 (tuple): A tuple containing values from the left or right split \n",
    "                    or all data for the target value\n",
    "\n",
    "    Returns:\n",
    "        tuple of tuples: Tuple indexed by key value (feat, split) with values:\n",
    "                         ((sum of left split values,sum of right split values),\n",
    "                          (squared sum of left split values, squared sum of right split values),\n",
    "                          (count of left split values, count of right split values))\n",
    "                        or\n",
    "                         ((0,sum of target values),\n",
    "                          (0, squared sum of target values),\n",
    "                          (0, count of target values))\n",
    "                        \n",
    "    \"\"\"\n",
    "    return  ((t1[0][0]+t2[0][0],t1[0][1]+t2[0][1]), \n",
    "             (t1[1][0]+t2[1][0],t1[1][1]+t2[1][1]),\n",
    "             (t1[2][0]+t2[2][0],t1[2][1]+t2[2][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_stats(t):\n",
    "    \"\"\"Calculates the mean, variance and the coefficient of variation (CV) for each (feat, split) \n",
    "       and for the full (unsplited) data.\n",
    "\n",
    "    Args:\n",
    "        t (tuple): A tuple received from the function soma\n",
    "\n",
    "    Returns:\n",
    "        A tuple with tuples ((feat,split),(left variance, left CV, left count),\n",
    "                                          (right variance, right CV, right count) )\n",
    "    \"\"\"\n",
    "    if t[1][2][0] > 0:\n",
    "        mmenor = t[1][0][0] / t[1][2][0]\n",
    "        sdmenor = (t[1][1][0] - (t[1][0][0]**2 / t[1][2][0]))/(t[1][2][0])\n",
    "        cvmenor = np.sqrt(sdmenor)/mmenor*100\n",
    "        menor = (sdmenor, cvmenor,t[1][2][0])\n",
    "    else:\n",
    "        menor = (0, 0, 0)\n",
    "    \n",
    "    if t[1][2][1] > 0:    \n",
    "        mmaior = t[1][0][1] / t[1][2][1]\n",
    "        sdmaior = (t[1][1][1] - (t[1][0][1]**2 / t[1][2][1]))/(t[1][2][1])\n",
    "        cvmaior = np.sqrt(sdmaior)/mmaior*100\n",
    "        maior = (sdmaior, cvmaior,t[1][2][1])\n",
    "    else:\n",
    "        maior = (0, 0, 0)\n",
    "    return (t[0], menor, maior)\n",
    "\n",
    "def informationGain(t,c):\n",
    "    \"\"\"Calculates de Information Gain.\n",
    "\n",
    "    Args:\n",
    "        t (tuple): tuple with ((feat,split),(left variance, left CV, left count),\n",
    "                                                 (right variance, right CV, right count))\n",
    "        c (tuple): tuple with ((target,full),(0, 0, 0),(full variance, full CV, full count))\n",
    "\n",
    "    Returns:\n",
    "        tuple with ((feat,split), informationGain, (left CV,right CV))\n",
    "    \"\"\"\n",
    "    return ((t[0], c[2][0] - (t[1][2]/c[2][2])*t[1][0] - (t[2][2]/c[2][2])*t[2][0], (t[1][1], t[2][1]))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infoGainSplit(lpRDD,feats,splits):\n",
    "    \"\"\"Select the tuple (feat,split) with the greatest information gain\n",
    "\n",
    "    Args:\n",
    "        lpRDD (RDD): The dataset. It can be complete or splited.\n",
    "        feats (list): List with the attribute indexes.\n",
    "        splits (list): List with all the splits candidates.\n",
    "\n",
    "    Returns:\n",
    "        e (tuple): A tuple containing the split with max information gain. Also contains left and right CVs.\n",
    "                   ((feat,split), maxInformationGain, (left CV,right CV))\n",
    "    \"\"\"\n",
    "    results = lpRDD.flatMap(lambda lp: contador(lp,feats,splits)).reduceByKey(soma)    \n",
    "    statistics = results.map(lambda c: calc_stats(c))    \n",
    "    classe = statistics.filter(lambda x: x[0][0]==3).collect()[0]\n",
    "    es = statistics.filter(lambda x: x[0][0]<3).map(lambda x: informationGain(x,classe)).collect()          \n",
    "    e = max(es, key = lambda t: t[1]) #atributo / split escolhido   \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(lpRDD, e):\n",
    "    \"\"\"Splits the data given a chosen (feat,split).\n",
    "\n",
    "    Args:\n",
    "        lpRDD (RDD): The dataset. It can be complete or splited.\n",
    "        e (tuple): Chosen (feat,split) with max Information Gain.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple with RDDs splited at attribute feat and value split: (leftRDD,rightRDD)\n",
    "    \"\"\"\n",
    "    if e[0][0]<2:\n",
    "            menorRDD = lpRDD.filter(lambda v: v['features'][e[0][0]]<e[0][1])\n",
    "            maiorRDD = lpRDD.filter(lambda v: v['features'][e[0][0]]>e[0][1])\n",
    "    elif e[0][0]==2:\n",
    "            menorRDD = lpRDD.filter(lambda v: v['features'][e[0][0]] in e[0][1])\n",
    "            maiorRDD = lpRDD.filter(lambda v: v['features'][e[0][0]] not in e[0][1])\n",
    "    return (menorRDD,maiorRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeTree(lpRDD, maxDepth=1, currDepth=0, st=None, arvore={}, pos=0):\n",
    "    \"\"\"Build the Decision Tree model. This function should not be called by the user. \n",
    "       Call buildTree instead.\n",
    "\n",
    "    Args:\n",
    "        lpRDD (RDD): The dataset. It can be complete or splited.\n",
    "        maxDepth (int): the max depth the tree can grow.\n",
    "        currDepth (int): Current depth of the tree. Should not be changed.\n",
    "        st (tuple): Tuple with the statistics of the chosen split. Should not be changed.\n",
    "        arvore (dict): The model which will be returned at the end of the processing. Should not be changed.\n",
    "        pos (int): Position of the node on the tree. Should not be changed.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with 's' added to it.\n",
    "    \"\"\"\n",
    "    if st!=None:\n",
    "        if st[0]<10 or maxDepth<currDepth:\n",
    "            media = lpRDD.map(lambda x: x['label']).mean()\n",
    "            arvore[pos] = media\n",
    "            return arvore \n",
    "    \n",
    "\n",
    "    feats,splits = makeSplits(lpRDD)\n",
    "    \n",
    "    e = infoGainSplit(lpRDD,feats,splits)\n",
    "    \n",
    "    menorRDD,maiorRDD = splitData(lpRDD, e)\n",
    "    \n",
    "    arvore[pos] = e[0]\n",
    "    \n",
    "    amenor = makeTree(menorRDD, maxDepth, currDepth+1,(e[2][0], e[1]),arvore,pos=(2*pos+1))\n",
    "    amaior = makeTree(maiorRDD, maxDepth, currDepth+1,(e[2][1], e[1]),arvore,pos=(2*pos+2))\n",
    "    return arvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTree(lpRDD, maxDepth=1):\n",
    "    \"\"\"Build the Decision Tree model.\n",
    "\n",
    "    Args:\n",
    "        lpRDD (RDD): The full dataset.\n",
    "        maxDepth (int): the max depth the tree can grow (deeper leafs will be on depth maxDepth+1)\n",
    "\n",
    "    Returns:\n",
    "        dict: The decision Tree model.\n",
    "    \"\"\"\n",
    "    return makeTree(lpRDD, maxDepth=1, currDepth=0, st=None, arvore={}, pos=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(arvore, lp):\n",
    "    def pred(arvore, lp, i=0):\n",
    "        \"\"\"Makes a prediction.\n",
    "\n",
    "        Args:\n",
    "            arvore (dict): The decision Tree model.\n",
    "            lp (dict): A new data we wish to determine the target value.\n",
    "            i (int): position on the tree. Should not be changed by the user.\n",
    "\n",
    "        Returns:\n",
    "            str: A string with 's' added to it.\n",
    "        \"\"\"\n",
    "        if type(arvore[i]) != tuple:\n",
    "            if arvore[i]!=0:\n",
    "                return (lp['label'], arvore[i])\n",
    "            else:\n",
    "                return (lp['label'], lp['label'])\n",
    "\n",
    "        node = arvore[i]\n",
    "\n",
    "        if node[0]<2:\n",
    "            if lp['features'][node[0]]<node[1]:\n",
    "                return pred(arvore, lp, 2*i+1)\n",
    "            else:\n",
    "                return pred(arvore, lp, 2*i+2)\n",
    "        elif node[0]==2:\n",
    "            if lp['features'][node[0]] in node[1]:\n",
    "                return pred(arvore, lp, 2*i+1)\n",
    "            else:\n",
    "                return pred(arvore, lp, 2*i+2)\n",
    "    return pred(arvore, lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcError(lpTest, arvore):\n",
    "    \"\"\"Calculates the Residual Sum of Squares for predictions on a test set.\n",
    "\n",
    "    Args:\n",
    "        lpTest (RDD): A test dataset with data unseen on training.\n",
    "        arvore (dict): The decision Tree model.\n",
    "\n",
    "    Returns:\n",
    "        int: The Residual Sum of Squares of the predictions.\n",
    "    \"\"\"\n",
    "    sqr = lpTest.map(lambda x: predict(arvore, x)).map(lambda x: (x[0]-x[1])**2).sum()\n",
    "    return sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savetree(arvore, filename):\n",
    "    \"\"\"Saves the model to disk\n",
    "\n",
    "    Args:\n",
    "        arvore (dict): The decision Tree model.\n",
    "        filename (str): String with the saved model filename\n",
    "\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(arvore, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readtree(filename):\n",
    "    \"\"\"Load the model from disk.\n",
    "\n",
    "    Args:\n",
    "        filename (str): String with the saved model filename\n",
    "\n",
    "    Returns:\n",
    "        arvore (dict): The decision Tree model.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as handle:\n",
    "        arvore = pickle.load(handle)\n",
    "    return arvore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treeimage(arvore, filename):\n",
    "    \"\"\"Generates a visualization of the model and save to an image file.\n",
    "       Needs PyDot and standalone application Graphviz installed.\n",
    "\n",
    "    Args:\n",
    "        arvore (dict): The decision Tree model.\n",
    "        filename (str): the image filename.\n",
    "        \n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    for v,l in arvore.items():\n",
    "        if type(l)==tuple:\n",
    "            if type(l[1])!=tuple:\n",
    "                G.add_node(v,label=(l[0],'{0:.2f}'.format(l[1])))\n",
    "            else:\n",
    "                G.add_node(v,label=l)\n",
    "            \n",
    "        else:\n",
    "            G.add_node(v,label='{0:.2f}'.format(l))\n",
    "\n",
    "    for v in G.nodes():\n",
    "    \n",
    "        if 2*v+1 in G:\n",
    "            G.add_edge(v,2*v+1)\n",
    "        if 2*v+2 in G:\n",
    "            G.add_edge(v,2*v+2)\n",
    "\n",
    "    os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "    p=nx.drawing.nx_pydot.to_pydot(G)\n",
    "    p.write_png(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo total de construção paralelizado (local[4]): 297.28 segundos\n"
     ]
    }
   ],
   "source": [
    "ti=time.time()\n",
    "arvore = buildTree(lpRDD,maxDepth=1)\n",
    "tf = time.time()\n",
    "print('Tempo total de construção paralelizado (local[4]): %.2f segundos'%(tf-ti))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103.74703903274495\n"
     ]
    }
   ],
   "source": [
    "print(calcError(lpTest, arvore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
